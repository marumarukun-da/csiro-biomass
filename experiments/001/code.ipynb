{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kaggle Submission Notebook for CSIRO Biomass Prediction\n",
    "========================================================\n",
    "This notebook runs inference using trained models and creates submission.csv\n",
    "\n",
    "Usage:\n",
    "1. Train models locally: python train.py --config configs/exp/exp001.yaml\n",
    "2. Upload artifacts to Kaggle as a Model\n",
    "3. Run this notebook on Kaggle with the artifacts attached\n",
    "\"\"\"\n",
    "\n",
    "import config\n",
    "import pandas as pd\n",
    "\n",
    "# Check environment\n",
    "print(f\"Running in Kaggle: {config.IS_KAGGLE_ENV}\")\n",
    "print(f\"Input directory: {config.INPUT_DIR}\")\n",
    "print(f\"Output directory: {config.OUTPUT_DIR}\")\n",
    "print(f\"Artifact directory: {config.ARTIFACT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "from inference import kaggle_inference\n",
    "\n",
    "# Configuration\n",
    "RUN_ID = \"run_0001\"  # Change this to match your best run\n",
    "FOLDS = None  # None = use all 5 folds, or specify list like [1, 2, 3]\n",
    "USE_SPLIT = False  # Whether to use left-right image splitting TTA\n",
    "USE_TTA = True  # Whether to use Test Time Augmentation\n",
    "USE_EMA = True  # Whether to use EMA weights\n",
    "IMG_SIZE = 224  # Image size (must match training)\n",
    "\n",
    "# Run inference and create submission\n",
    "submission_df = kaggle_inference(\n",
    "    run_id=RUN_ID,\n",
    "    folds=FOLDS,\n",
    "    use_split=USE_SPLIT,\n",
    "    use_tta=USE_TTA,\n",
    "    use_ema=USE_EMA,\n",
    "    img_size=IMG_SIZE,\n",
    ")\n",
    "\n",
    "# Save submission\n",
    "submission_df.to_csv(config.OUTPUT_DIR / \"submission.csv\", index=False)\n",
    "print(f\"Submission saved to {config.OUTPUT_DIR / 'submission.csv'}\")\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "submission_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload artifacts to Kaggle (run this locally after training)\n",
    "# Uncomment and run this cell to upload trained models and code\n",
    "\n",
    "# if not config.IS_KAGGLE_ENV:\n",
    "#     from src.kaggle_utils.customhub import dataset_upload, model_upload\n",
    "#\n",
    "#     # Upload trained model weights as Kaggle Model\n",
    "#     model_upload(\n",
    "#         handle=config.ARTIFACTS_HANDLE,\n",
    "#         local_model_dir=config.OUTPUT_DIR,\n",
    "#         update=False,  # Set to True to update existing model\n",
    "#     )\n",
    "#\n",
    "#     # Upload code as Kaggle Dataset\n",
    "#     dataset_upload(\n",
    "#         handle=config.CODES_HANDLE,\n",
    "#         local_dataset_dir=config.ROOT_DIR,\n",
    "#         update=True,\n",
    "#     )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
