{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Data Experiment\n",
    "\n",
    "This notebook is a template for tabular data competitions using GBDT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import config\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from metric import score\n",
    "from seed import seed_everything\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Configuration\n",
    "# =============================================================================\n",
    "class CFG:\n",
    "    SEED = 42\n",
    "    N_FOLDS = 5\n",
    "    TARGET_COL = \"target\"  # Update with your target column\n",
    "    \n",
    "    # Paths from config.py\n",
    "    DATA_PATH = config.COMP_DATASET_DIR\n",
    "    OUTPUT_DIR = config.OUTPUT_DIR\n",
    "    MODEL_PATH = config.OUTPUT_DIR / \"models\"\n",
    "    \n",
    "    # LightGBM parameters\n",
    "    lgb_params = {\n",
    "        \"objective\": \"regression\",  # or \"binary\", \"multiclass\"\n",
    "        \"metric\": \"rmse\",\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 6,\n",
    "        \"num_leaves\": 31,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"subsample\": 0.8,\n",
    "        \"seed\": SEED,\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "    \n",
    "    NUM_BOOST_ROUND = 10000\n",
    "    EARLY_STOPPING_ROUND = 100\n",
    "\n",
    "seed_everything(CFG.SEED)\n",
    "CFG.MODEL_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Load Data\n",
    "# =============================================================================\n",
    "train = pl.read_csv(CFG.DATA_PATH / \"train.csv\")\n",
    "test = pl.read_csv(CFG.DATA_PATH / \"test.csv\")\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Feature Engineering\n",
    "# =============================================================================\n",
    "# TODO: Add your feature engineering here\n",
    "\n",
    "# Define features\n",
    "FEATURES = [col for col in train.columns if col not in [\"id\", CFG.TARGET_COL]]\n",
    "print(f\"Number of features: {len(FEATURES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Cross-Validation Training\n",
    "# =============================================================================\n",
    "train_pd = train.to_pandas()\n",
    "test_pd = test.to_pandas()\n",
    "\n",
    "oof_predictions = np.zeros(len(train_pd))\n",
    "test_predictions = np.zeros(len(test_pd))\n",
    "\n",
    "kf = KFold(n_splits=CFG.N_FOLDS, shuffle=True, random_state=CFG.SEED)\n",
    "# For classification: kf = StratifiedKFold(n_splits=CFG.N_FOLDS, shuffle=True, random_state=CFG.SEED)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_pd), 1):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    X_train = train_pd.loc[train_idx, FEATURES]\n",
    "    y_train = train_pd.loc[train_idx, CFG.TARGET_COL]\n",
    "    X_val = train_pd.loc[val_idx, FEATURES]\n",
    "    y_val = train_pd.loc[val_idx, CFG.TARGET_COL]\n",
    "    \n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        CFG.lgb_params,\n",
    "        train_data,\n",
    "        num_boost_round=CFG.NUM_BOOST_ROUND,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        valid_names=[\"train\", \"valid\"],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=CFG.EARLY_STOPPING_ROUND),\n",
    "            lgb.log_evaluation(500),\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    oof_predictions[val_idx] = model.predict(X_val)\n",
    "    test_predictions += model.predict(test_pd[FEATURES]) / CFG.N_FOLDS\n",
    "    \n",
    "    # Save model\n",
    "    model_path = CFG.MODEL_PATH / f\"lgb_fold{fold}.pkl\"\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # Fold score\n",
    "    fold_score = score(y_val.values, oof_predictions[val_idx])\n",
    "    print(f\"Fold {fold} Score: {fold_score:.6f}\")\n",
    "    \n",
    "    del X_train, y_train, X_val, y_val, model\n",
    "    gc.collect()\n",
    "\n",
    "# Overall CV score\n",
    "cv_score = score(train_pd[CFG.TARGET_COL].values, oof_predictions)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Overall CV Score: {cv_score:.6f}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Save OOF and Test Predictions\n",
    "# =============================================================================\n",
    "# Save OOF predictions\n",
    "oof_df = pd.DataFrame({\n",
    "    \"id\": train_pd[\"id\"],\n",
    "    \"oof_pred\": oof_predictions,\n",
    "    \"true\": train_pd[CFG.TARGET_COL],\n",
    "})\n",
    "oof_df.to_csv(CFG.OUTPUT_DIR / \"oof_predictions.csv\", index=False)\n",
    "\n",
    "# Save test predictions (for local use)\n",
    "test_pred_df = pd.DataFrame({\n",
    "    \"id\": test_pd[\"id\"],\n",
    "    \"pred\": test_predictions,\n",
    "})\n",
    "test_pred_df.to_csv(CFG.OUTPUT_DIR / \"test_predictions.csv\", index=False)\n",
    "\n",
    "print(f\"OOF predictions saved to: {CFG.OUTPUT_DIR / 'oof_predictions.csv'}\")\n",
    "print(f\"Test predictions saved to: {CFG.OUTPUT_DIR / 'test_predictions.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Create Submission (for local testing)\n",
    "# =============================================================================\n",
    "sub_df = pl.read_csv(CFG.DATA_PATH / \"sample_submission.csv\")\n",
    "# TODO: Update with your target column and predictions\n",
    "# sub_df = sub_df.with_columns(pl.Series(CFG.TARGET_COL, test_predictions))\n",
    "sub_df.write_csv(CFG.OUTPUT_DIR / \"submission.csv\")\n",
    "\n",
    "print(f\"Submission saved to: {CFG.OUTPUT_DIR / 'submission.csv'}\")\n",
    "print(sub_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
