# Experiment 001 実装ガイド

このドキュメントは `experiments/001` フォルダの実装内容と、Kaggle への提出手順を詳細に説明します。

---

## 目次

1. [概要](#概要)
2. [ファイル構成](#ファイル構成)
3. [モデルアーキテクチャ](#モデルアーキテクチャ)
4. [設定ファイル（YAML）](#設定ファイルyaml)
5. [トレーニング手順](#トレーニング手順)
6. [推論手順](#推論手順)
7. [Kaggle提出手順](#kaggle提出手順)
8. [グリッドサーチの仕組み](#グリッドサーチの仕組み)
9. [重要な実装の詳細](#重要な実装の詳細)
10. [トラブルシューティング](#トラブルシューティング)

---

## 概要

### コンペティション

- **名前**: CSIRO Biomass Prediction
- **タスク**: 牧草地の画像から5つのバイオマス指標を予測（回帰タスク）
- **評価指標**: Globally Weighted R² Score

### 予測対象

| ターゲット | 重み | 予測/導出 |
|-----------|------|----------|
| Dry_Total_g | 0.5 | 予測 |
| GDM_g | 0.2 | 予測 |
| Dry_Green_g | 0.1 | 予測 |
| Dry_Dead_g | 0.1 | 導出: `Dry_Total_g - GDM_g` |
| Dry_Clover_g | 0.1 | 導出: `GDM_g - Dry_Green_g` |

**重要**: モデルは3つの値のみを予測し、残り2つは数式で導出します。

### 設計方針

- pj_kenpin スタイルの YAML 駆動グリッドサーチ
- Kaggle 環境との互換性維持（IS_KAGGLE_ENV による自動パス切り替え）
- 5-fold CV + EMA + TTA による堅牢な予測

---

## ファイル構成

```
experiments/001/
├── config.py                    # パス設定、環境判定
├── train.py                     # トレーニングスクリプト（グリッドサーチ対応）
├── inference.py                 # 推論スクリプト（TTA・アンサンブル対応）
├── code.ipynb                   # Kaggle 提出用ノートブック
│
├── configs/
│   ├── base/
│   │   └── exp_template.yaml    # 基本設定テンプレート
│   └── exp/
│       └── exp001.yaml          # 実験設定（これを編集）
│
└── src/
    ├── __init__.py
    ├── seed.py                  # 再現性のためのシード設定
    ├── metric.py                # Weighted R² スコア計算
    ├── loss_function.py         # 損失関数（Weighted Smooth L1）
    ├── model.py                 # モデル定義（DualInputRegressionNet）
    └── data.py                  # データセット、DataLoader、Augmentation
```

---

## モデルアーキテクチャ

### DualInputRegressionNet

左右分割画像を入力とするSiamese-likeアーキテクチャです。

```
Original Image [1000, 2000, 3]
         │
    ┌────┴────┐
    │ Split   │
    ▼         ▼
Left Half   Right Half
[1000,1000] [1000,1000]
    │         │
    ▼         ▼
┌─────────────────────┐
│  Shared Backbone    │  (EfficientNetV2, ConvNeXt, Swin 等)
│  (timm pretrained)  │
└─────────────────────┘
    │         │
    ▼         ▼
┌─────────────────────┐
│  GeM Pooling        │  (Generalized Mean Pooling, 学習可能なp)
└─────────────────────┘
    │         │
    ▼         ▼
[num_feat]  [num_feat]
    │         │
    └────┬────┘
         │ Concatenate
         ▼
  [num_features * 2]
         │
┌─────────────────────┐
│  MLP Head           │
│  - Dropout          │
│  - Linear → 512     │
│  - GELU             │
│  - Dropout          │
│  - Linear → 3       │
└─────────────────────┘
         │
         ▼ [B, 3]
Output: [Dry_Total_g, GDM_g, Dry_Green_g]
```

### GeM Pooling

通常の Average Pooling より柔軟なプーリング手法：

```python
GeM(x) = (1/|X| * Σ x^p)^(1/p)
```

- `p=1`: Average Pooling
- `p→∞`: Max Pooling
- `p` は学習可能パラメータ（デフォルト: 3.0）

### 推奨バックボーン

timm ライブラリで利用可能なバックボーンを使用できます。

```python
# EfficientNet V2 (速度と精度のバランスが良い)
"tf_efficientnetv2_b0.in1k"   # 速度重視（ベースライン向け）
"tf_efficientnetv2_b1.in1k"   # 速度重視
"tf_efficientnetv2_b2.in1k"   # バランス型
"tf_efficientnetv2_s.in1k"    # バランス型
"tf_efficientnetv2_m.in1k"    # 精度重視

# ConvNeXt (モダンなCNNアーキテクチャ)
"convnext_tiny.fb_in1k"       # バランス型
"convnext_small.fb_in1k"      # 精度重視
"convnext_base.fb_in1k"       # 精度重視

# Swin Transformer
"swin_tiny_patch4_window7_224.ms_in1k"   # バランス型
"swin_small_patch4_window7_224.ms_in1k"  # 精度重視

# EfficientNet (オリジナル)
"tf_efficientnet_b0.ns_jft_in1k"  # 速度重視
"tf_efficientnet_b1.ns_jft_in1k"  # バランス型
"tf_efficientnet_b2.ns_jft_in1k"  # バランス型
```

---

## 設定ファイル（YAML）

### 構造

```yaml
# configs/exp/exp001.yaml

__include__:                    # 継承元（base template）
  - "../base/exp_template.yaml"

experiment:
  name: exp001
  seed: 42
  output_dir: null              # null = config.py のデフォルト値を使用
  notes: "Baseline experiment"

dataset:
  train_csv: null               # null = config.py のデフォルト値を使用
  image_dir: null               # null = config.py のデフォルト値を使用
  img_size:
    - 224                       # リスト = グリッドサーチ対象

trainer:
  train_batch_size: 32
  val_batch_size: 64
  num_workers: 4
  num_epochs: 10
  use_amp: true
  n_folds: 5
  fold: null                    # null = 全fold、数値 = 指定foldのみ

optimization:
  lr:
    - 1e-3                      # リスト = グリッドサーチ対象
    - 1e-4
  weight_decay: 1e-4
  warmup_rate: 0.1
  use_ema: true
  ema_decay: 0.995

model:
  backbone:
    - tf_efficientnetv2_b0.in1k  # リスト = グリッドサーチ対象
    - tf_efficientnetv2_b1.in1k
  pretrained: true
  num_outputs: 3
  dropout: 0.2
  hidden_size: 512

loss:
  beta: 1.0                      # Smooth L1 の beta パラメータ
  weights:                       # ターゲット重み（グリッドサーチ対象外）
    Dry_Total_g: 0.5
    GDM_g: 0.2
    Dry_Green_g: 0.1

augmentation:
  normalize:
    mean: [0.485, 0.456, 0.406]  # ImageNet (グリッドサーチ対象外)
    std: [0.229, 0.224, 0.225]
  train:
    horizontal_flip:
      p: 0.5
    vertical_flip:
      p: 0.5
```

### グリッドサーチ対象外のパス

以下のパスはリストでもグリッドサーチの対象になりません：

```python
NON_SWEEP_PATHS = {
    ("experiment", "notes"),
    ("dataset", "target_cols"),
    ("loss", "weights"),
    ("augmentation", "normalize", "mean"),
    ("augmentation", "normalize", "std"),
}
```

---

## トレーニング手順

### 1. 環境準備

```bash
cd /path/to/csiro-biomass

# 必要なライブラリ（主要なもの）
# pip install torch torchvision timm albumentations transformers omegaconf scikit-learn tqdm matplotlib
```

### 2. トレーニング実行

```bash
cd experiments/001

# 基本実行
python train.py --config configs/exp/exp001.yaml
```

### 3. 出力構造

```
data/output/001/1/
└── {timestamp}_{experiment_name}/        # experiment_dir
    ├── summary.csv                       # 全 run の結果一覧（R²降順）
    ├── summary.json                      # JSON 形式のサマリー
    │
    ├── 001_tf_efficientnetv2_b0_in1k__img_size-224__lr-0_001/   # run_name
    │   ├── config.yaml                   # この run の設定
    │   ├── weights/
    │   │   ├── best_fold0.pth            # 各 fold のベストモデル（EMA使用時はEMA重み）
    │   │   ├── best_fold1.pth
    │   │   ├── ...
    │   │   └── best_fold4.pth
    │   ├── logs/
    │   │   ├── train.log                 # トレーニングログ
    │   │   └── metrics.csv               # fold 別メトリクス
    │   └── plots/
    │       └── training_curves.png       # 全foldを色分けして表示 + 平均（黒破線）
    │
    ├── 002_tf_efficientnetv2_b1_in1k__img_size-224__lr-0_001/
    │   └── ...
    └── ...
```

**training_curves.png について**:
- 3パネル構成: Train Loss / Validation Loss / Validation R²
- 各foldを異なる色で表示
- 複数fold時は平均カーブを黒破線で重ねて表示

### 4. 結果の確認

```python
import pandas as pd

# summary.csv を確認
df = pd.read_csv("output/{timestamp}_exp001/summary.csv")
print(df[["run_name", "avg_val_r2", "model/backbone", "optimization/lr"]])
```

---

## 推論手順

### ローカルでの推論

```bash
cd experiments/001

# 基本実行
python inference.py \
    --experiment_dir "20251212_111833_exp001" \
    --run_name "001_tf_efficientnetv2_b0_in1k__img_size-224__lr-0_001"

# オプション
python inference.py \
    --experiment_dir "20251212_111833_exp001" \
    --run_name "001_tf_efficientnetv2_b0_in1k__img_size-224__lr-0_001" \
    --folds 0,1,2 \      # 特定の fold のみ使用（デフォルト: all）
    --img_size 224 \     # 画像サイズ（デフォルト: 224）
    --device cuda        # デバイス（デフォルト: cuda）
```

**注意**: TTA は常に有効です（無効化オプションなし）。

### 出力ファイル

```
{run_dir}/
├── submission.csv    # Kaggle 提出用（Long format）
└── predictions.csv   # 分析用（Wide format, 3列）
```

---

## Kaggle提出手順

### ワークフロー図

```
┌─────────────────────────────────────────────────────────────────┐
│                         ローカル環境                             │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  1. トレーニング実行                                              │
│     python train.py --config configs/exp/exp001.yaml            │
│                          │                                      │
│                          ▼                                      │
│     data/output/001/1/{timestamp}_exp001/                        │
│     ├── 001_xxx/weights/best_fold*.pth                          │
│     └── summary.csv                                              │
│                          │                                      │
│  2. ベストモデルを選択                                            │
│     summary.csv の avg_val_r2 が最高の run_name を確認           │
│                          │                                      │
│  3. Kaggle Model としてアップロード                               │
│     {run_name}/ ディレクトリをアップロード                        │
│     ※ {timestamp}_exp001/ は含めない                             │
│                          │                                      │
└──────────────────────────┼──────────────────────────────────────┘
                           │
                           ▼
┌─────────────────────────────────────────────────────────────────┐
│                        Kaggle 環境                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  Input:                                                         │
│  ├── csiro-biomass/              # コンペデータ                  │
│  │   ├── test.csv                                               │
│  │   └── (images)                                               │
│  └── csiro-biomass-artifacts/    # アップロードしたモデル         │
│      └── other/001/1/                                           │
│          └── {run_name}/         # run_name で直接アクセス       │
│              ├── weights/                                        │
│              │   └── best_fold*.pth                              │
│              └── config.yaml                                     │
│                                                                 │
│  4. code.ipynb を実行                                            │
│     → kaggle_inference(run_name="...") を呼び出し               │
│     → submission.csv が生成される                                │
│                                                                 │
│  Output:                                                        │
│  └── submission.csv              # 提出ファイル                  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 詳細手順

#### Step 1: トレーニング（ローカル）

```bash
cd experiments/001
python train.py --config configs/exp/exp001.yaml
```

#### Step 2: 結果確認

```bash
# summary.csv を確認してベストモデルを特定
cat output/{timestamp}_exp001/summary.csv
```

#### Step 3: モデルとコードをアップロード

`code.ipynb` の最後のセルで **EXPERIMENT_DIR を指定** してアンコメント・実行：

```python
# アップロードする experiment_dir を指定
# data/output/001/1/ 内のディレクトリ名を確認して設定
EXPERIMENT_DIR = "20251212_111833_exp001"  # ← ここを変更

if not config.IS_KAGGLE_ENV:
    from src.kaggle_utils.customhub import dataset_upload, model_upload

    experiment_path = config.OUTPUT_DIR / EXPERIMENT_DIR
    if not experiment_path.exists():
        raise FileNotFoundError(f"Experiment directory not found: {experiment_path}")

    print(f"Uploading experiment: {experiment_path}")

    # モデル重みを Kaggle Model としてアップロード
    # experiment_dir 内の全 run_name をアップロード（アンサンブル用に全て保持）
    model_upload(
        handle=config.ARTIFACTS_HANDLE,
        local_model_dir=experiment_path,
        update=False,  # 更新時は True
    )

    # 実験コードを Kaggle Dataset としてアップロード
    dataset_upload(
        handle=config.CODES_HANDLE,
        local_dataset_dir=config.EXP_DIR,
        update=True,
    )
```

**アップロードされる内容：**
- `csiro-biomass-artifacts`: 指定した experiment_dir 内の全 run_name（モデル重み、config.yaml、summary.csv 等）
- `csiro-biomass-codes-001`: 実験001のコード（`config.py`, `inference.py`, `src/` 等）

**注意**:
- **EXPERIMENT_DIR**: 同じ実験で複数回学習した場合、アップロードしたい experiment_dir を明示的に指定
- **コードDataset名**: 実験名が含まれる（`csiro-biomass-codes-{EXP_NAME}`）ので実験間で上書きされない

#### Step 4: Kaggle Notebook 作成と提出

**手動で新しいコードを作る必要はありません。** `code.ipynb` をアップロードして実行するだけです。

1. **Kaggle コンペページ** → 「Code」タブ → 「New Notebook」をクリック
2. **File → Upload Notebook** で `experiments/001/code.ipynb` をアップロード
3. **右側パネル「+ Add Input」** で以下のデータソースを追加：
   - `csiro-biomass`（コンペデータ）- Competition Data から追加
   - `csiro-biomass-artifacts`（モデル重み）- Your Work → Models から追加
   - `csiro-biomass-codes-001`（実験001コード）- Your Work → Datasets から追加
4. **セル1（推論セル）** の `RUN_NAME` を実際のベストモデル名に変更：
   ```python
   # summary.csv で確認した最良の run_name を指定
   RUN_NAME = "001_tf_efficientnetv2_b0_in1k__img_size-224__lr-0_001"
   ```
5. **Run All** で全セルを実行
6. 右上の **Submit** ボタンをクリック

##### なぜ Kaggle では experiment_dir が不要か？

ローカルとKaggleでディレクトリ構造が異なります：

**ローカル**（2階層）:
```
data/output/001/1/
└── {experiment_dir}/          # 20251212_111833_exp001（タイムスタンプ付き）
    └── {run_name}/            # 001_tf_efficientnetv2_b0_in1k__...
```

**Kaggle**（1階層）:
```
/kaggle/input/csiro-biomass-artifacts/other/001/1/
└── {run_name}/                # experiment_dir は省略してアップロード
```

アップロード時に `{experiment_dir}/` を含めず `{run_name}/` ディレクトリだけをアップロードするため、Kaggle上では `run_name` のみで直接アクセスできます。

##### 推論パラメータについて

| パラメータ | 説明 | デフォルト |
|-----------|------|----------|
| `run_name` | アップロードしたモデルのディレクトリ名 | （必須） |
| `folds` | 使用するfold番号のリスト | `None`（全5fold） |
| `img_size` | 画像サイズ（学習時と同じ値） | `224` |

**注意**:
- TTA は常に有効です（無効化オプションなし）
- EMA重みは学習時に自動で `best_fold*.pth` として保存されています

---

## グリッドサーチの仕組み

### 動作原理

1. YAML ファイルをパース
2. リスト値を持つパラメータを抽出（NON_SWEEP_PATHS を除く）
3. すべての組み合わせを生成
4. 各組み合わせで独立したトレーニングを実行

### 例

```yaml
model:
  backbone:
    - tf_efficientnetv2_b0.in1k
    - tf_efficientnetv2_b1.in1k

optimization:
  lr:
    - 1e-3
    - 1e-4
```

この場合、以下の4つの run が生成されます：

| Run | backbone | lr |
|-----|----------|-----|
| 001 | efficientnetv2_b0 | 1e-3 |
| 002 | efficientnetv2_b0 | 1e-4 |
| 003 | efficientnetv2_b1 | 1e-3 |
| 004 | efficientnetv2_b1 | 1e-4 |

### experiment_dir と run_name について

トレーニング出力は以下のディレクトリ構造で保存されます：

```
data/output/001/1/
└── {timestamp}_{exp_name}/              # experiment_dir (例: 20251212_111833_exp001)
    └── {index}_{backbone}__{params}/    # run_name (例: 001_tf_efficientnetv2_b0_in1k__img_size-224__lr-0_001)
```

**ローカル推論時**: `--experiment_dir` と `--run_name` の両方を指定

```bash
python inference.py \
    --experiment_dir "20251212_111833_exp001" \
    --run_name "001_tf_efficientnetv2_b0_in1k__img_size-224__lr-0_001"
```

**Kaggle推論時**: `run_name` のみ指定（アップロード時に experiment_dir は省略される）

```python
kaggle_inference(run_name="001_tf_efficientnetv2_b0_in1k__img_size-224__lr-0_001")
```

---

## 重要な実装の詳細

### 損失関数

```python
# Weighted Smooth L1 Loss
# 各ターゲットごとにバッチ平均のSmooth L1 Lossを計算し、重み付け合計

L_0 = mean(SmoothL1(pred[:, 0], target[:, 0]))  # Dry_Total_g
L_1 = mean(SmoothL1(pred[:, 1], target[:, 1]))  # GDM_g
L_2 = mean(SmoothL1(pred[:, 2], target[:, 2]))  # Dry_Green_g

loss = 0.5 * L_0 + 0.2 * L_1 + 0.1 * L_2

# SmoothL1 (beta=1.0):
# |x| < beta: 0.5 * x^2 / beta
# |x| >= beta: |x| - 0.5 * beta
```

### EMA (Exponential Moving Average)

```python
# モデル重みの指数移動平均を維持
# 学習の後半でより安定した重みを得られる

ema_weight = decay * ema_weight + (1 - decay) * model_weight

# デフォルト:
# - decay: 0.995
# - 開始: 総ステップの10%経過後
```

### TTA (Test Time Augmentation)

推論時に複数の変換を**分割前の元画像**に適用し、予測を平均：

```python
# TTA (3パターン) - 元画像に適用してから左右分割
transforms = [
    original,      # 変換なし
    hflip,         # 水平反転（左右が入れ替わる）
    vflip,         # 垂直反転
]

# 全 fold アンサンブル (例: 5fold × 3TTA = 15予測の平均)
```

### ターゲット導出

```python
def derive_all_targets(preds_3):
    """
    入力: [Dry_Total_g, GDM_g, Dry_Green_g]  # 予測値
    出力: [Dry_Green_g, Dry_Dead_g, Dry_Clover_g, GDM_g, Dry_Total_g]

    導出式:
    - Dry_Dead_g = max(Dry_Total_g - GDM_g, 0)
    - Dry_Clover_g = max(GDM_g - Dry_Green_g, 0)
    """
```

---

## トラブルシューティング

### よくあるエラー

#### 1. `FileNotFoundError: Train CSV not found`

```
原因: train_csv のパスが間違っている
解決: configs/exp/exp001.yaml の dataset.train_csv を確認
```

#### 2. `CUDA out of memory`

```
解決方法:
1. batch_size を減らす (32 → 16)
2. img_size を減らす (224 → 192)
3. 軽量なバックボーンを使用 (b1 → b0)
```

#### 3. `ModuleNotFoundError: No module named 'src'`

```
原因: 実行ディレクトリが experiments/001 ではない
解決: cd experiments/001 してから実行
```

#### 4. `KeyError: 'image_path'`

```
原因: train.csv のカラム名が想定と異なる
解決: src/data.py の image_col パラメータを確認
```

### デバッグ Tips

#### 1. 単一 fold で素早くテスト

```yaml
# configs/exp/exp001.yaml
trainer:
  fold: 0          # fold 0 のみ
  num_epochs: 2    # 2エポックのみ
```

#### 2. グリッドサーチを無効化

```yaml
# リストではなく単一値にする
model:
  backbone: tf_efficientnetv2_b0.in1k  # リストではない

optimization:
  lr: 1e-4  # リストではない
```

#### 3. ログの確認

```bash
# トレーニングログ
cat output/{timestamp}_exp001/001_xxx/logs/train.log

# fold 別メトリクス
cat output/{timestamp}_exp001/001_xxx/logs/metrics.csv
```

---

## 次のステップ（実験アイデア）

### 短期（精度向上）

1. **より大きなバックボーン**: `efficientnetv2_s`, `convnext_small`
2. **画像サイズ増加**: 224 → 384
3. **エポック数増加**: 10 → 30
4. **Augmentation 強化**: MixUp, CutMix

### 中期（アーキテクチャ）

1. **左右分割トレーニング**: `split_image: true`
2. **マルチスケール入力**: 複数解像度での学習
3. **損失関数の工夫**: Huber Loss, 組み合わせ損失

### 長期（アンサンブル）

1. **複数バックボーンの融合**: EfficientNet + ConvNeXt + Swin
2. **Pseudo Labeling**: テストデータの活用
3. **Stacking**: メタモデルによる統合

---

## 関連ドキュメント

- `docs/251209_compe_overview.md` - コンペ概要
- `docs/251209_data_explain.md` - データ形式の説明
- `docs/251209_baseline.md` - ベースライン戦略
- `docs/251209_implementation_plan.md` - 実装計画（詳細）
