# クロスバリデーション戦略の検討

## 概要

本ドキュメントでは、バイオマス予測タスクにおけるクロスバリデーション（CV）戦略を検討した結果をまとめる。
現状の単純なKFoldでは楽観的な評価になる可能性があり、より保守的で本番性能に近い評価を行うためのGroupKFold戦略を提案する。

---

## 現状のCV戦略

### 現在の実装（experiments/001/train.py）

```python
# 610行目付近
train_df = convert_long_to_wide(train_df)  # 1画像1行に変換（357行）
train_df = create_folds(train_df, n_folds=n_folds, seed=seed)  # 単純なKFold
```

- Long形式（1785行 = 357画像 × 5ターゲット）をWide形式（357行）に変換後、KFoldを適用
- 同じ画像が分割される問題は**解決済み**
- ただし、**同じサイトで撮影された複数画像がtrainとvalに分かれる**可能性がある

---

## 問題提起：サイト単位でのグループ化の必要性

### 背景

本番運用で未知のサイト（調査地点）の画像が入力された場合の性能を正しく評価するには、CVでも「未知のサイト」に対する評価を行うべきである。

### CVの種類と評価の特性

| CV方式 | 分割単位 | 評価の性質 |
|--------|---------|-----------|
| 通常KFold | 画像単位 | 既知サイトの一部で検証（楽観的） |
| GroupKFold | サイト単位 | 未知サイトで検証（保守的・現実的） |

---

## 「サイト」の定義

### 定義

データに明示的な「site」カラムは存在しないため、以下のように定義する：

```python
site = State + "_" + Sampling_Date
```

### 仮説

**同じ日に同じ州で撮影された画像は、似たような環境条件（気候、季節、天候）にあるため、バイオマス値も似た範囲になる傾向がある。**

この仮説が正しければ、同じサイトの画像をtrainとvalに分けると「似たもの同士」で評価することになり、本番性能より楽観的なCV評価になる。

---

## データ分析による仮説の検証

### サイト数と画像数

| 項目 | 値 |
|------|-----|
| 総画像数 | 357枚 |
| サイト数（State × Sampling_Date） | 30 |
| 州数（State） | 4（Tas, Vic, NSW, WA） |

### サイト内のtargetばらつき分析

| 指標 | 値 |
|------|-----|
| **全体のtarget標準偏差** | 15.82 |
| **サイト内標準偏差の平均** | 10.27 |

**結果：サイト内の方がばらつきが小さい → 仮説は妥当**

同じサイト（同じ日×同じ州）の画像は、ターゲット値が似ている傾向があることが確認された。

### サイト別統計（上位15サイト）

| サイト | 画像数 | target平均 | target標準偏差 | range |
|--------|-------|-----------|---------------|-------|
| Tas_2015/5/18 | 22 | 20.74 | 8.18 | 27.26 |
| Tas_2015/11/9 | 20 | 23.69 | 14.30 | 48.11 |
| Vic_2015/6/26 | 19 | 14.68 | 6.65 | 19.80 |
| Vic_2015/8/14 | 18 | 21.03 | 7.26 | 29.31 |
| Tas_2015/6/26 | 18 | 14.93 | 8.44 | 38.11 |
| NSW_2015/1/15 | 17 | 32.94 | 16.70 | 57.31 |
| Tas_2015/11/10 | 17 | 27.10 | 14.74 | 49.81 |
| Tas_2015/9/4 | 16 | 19.89 | 8.77 | 26.11 |
| NSW_2015/2/24 | 15 | 48.01 | 18.75 | 62.45 |
| NSW_2015/5/7 | 13 | 35.06 | 16.62 | 64.09 |
| WA_2015/7/8 | 12 | 13.44 | 7.98 | 24.97 |
| WA_2015/9/1 | 12 | 20.42 | 14.06 | 41.81 |
| NSW_2015/10/6 | 11 | 55.21 | 24.70 | 85.67 |
| Vic_2015/10/13 | 11 | 19.14 | 3.90 | 13.03 |
| Vic_2015/9/29 | 11 | 34.62 | 15.48 | 41.93 |

### Dry_Total_g（最重要指標）に絞った分析

本コンペでは5つの予測対象のうち、**Dry_Total_g（総乾燥バイオマス量）が最も重要視されている**。
そのため、Dry_Total_gに絞ったサイト内ばらつき分析も実施した。

#### サイト内のDry_Total_gばらつき分析

| 指標 | 値 |
|------|-----|
| **全体のDry_Total_g標準偏差** | 27.98 |
| **サイト内標準偏差の平均** | 18.54 |

**結果：Dry_Total_gでもサイト内の方がばらつきが小さい → 仮説は妥当**

#### 5ターゲット平均 vs Dry_Total_g の比較

| 指標 | 全体の標準偏差 | サイト内標準偏差の平均 | 比率（サイト内/全体） |
|------|--------------|---------------------|---------------------|
| 5ターゲット平均 | 15.82 | 10.27 | 0.65 |
| **Dry_Total_g** | 27.98 | 18.54 | 0.66 |

どちらの指標でも、サイト内のばらつきは全体の約65%程度であり、**サイト単位でのグループ化の妥当性が確認された**。

#### Dry_Total_gのサイト別統計（全30サイト）

| サイト | 画像数 | target平均 | target標準偏差 | range |
|--------|-------|-----------|---------------|-------|
| Tas_2015/5/18 | 22 | 39.60 | 15.86 | 57.41 |
| Tas_2015/11/9 | 20 | 45.11 | 26.13 | 86.00 |
| Vic_2015/6/26 | 19 | 28.70 | 12.59 | 41.14 |
| Vic_2015/8/14 | 18 | 36.59 | 12.43 | 49.80 |
| Tas_2015/6/26 | 18 | 29.92 | 15.89 | 65.93 |
| NSW_2015/1/15 | 17 | 58.34 | 27.13 | 94.50 |
| Tas_2015/11/10 | 17 | 51.76 | 29.16 | 92.29 |
| Tas_2015/9/4 | 16 | 39.64 | 20.38 | 60.33 |
| NSW_2015/2/24 | 15 | 82.17 | 30.70 | 103.50 |
| NSW_2015/5/7 | 13 | 65.42 | 33.76 | 134.40 |
| WA_2015/7/8 | 12 | 22.39 | 13.30 | 41.61 |
| WA_2015/9/1 | 12 | 34.04 | 23.43 | 69.69 |
| NSW_2015/10/6 | 11 | 103.23 | 42.88 | 145.10 |
| Vic_2015/10/13 | 11 | 39.66 | 7.80 | 27.50 |
| Vic_2015/9/29 | 11 | 58.96 | 26.12 | 70.94 |
| Tas_2015/7/1 | 10 | 29.37 | 11.90 | 36.45 |
| Tas_2015/6/29 | 10 | 24.64 | 12.21 | 38.44 |
| NSW_2015/4/1 | 10 | 42.16 | 22.87 | 71.50 |
| Vic_2015/9/30 | 10 | 78.00 | 20.46 | 55.37 |
| Vic_2015/8/18 | 10 | 49.70 | 12.05 | 41.90 |
| Vic_2015/7/2 | 10 | 20.69 | 3.92 | 12.90 |
| Tas_2015/9/11 | 9 | 32.53 | 13.75 | 41.96 |
| Vic_2015/7/1 | 9 | 31.19 | 12.63 | 33.70 |
| NSW_2015/2/25 | 9 | 76.18 | 29.45 | 80.60 |
| Tas_2015/9/3 | 9 | 28.36 | 9.18 | 28.26 |
| WA_2015/8/21 | 8 | 40.90 | 17.57 | 48.84 |
| Tas_2015/5/19 | 7 | 23.39 | 13.24 | 39.74 |
| Vic_2015/10/14 | 7 | 55.56 | 11.57 | 28.60 |
| Vic_2015/6/30 | 6 | 47.17 | 9.31 | 25.00 |
| Vic_2015/8/19 | 1 | 53.40 | - | 0.00 |

---

## 推奨するCV戦略：GroupKFold

### 実装方針

```python
from sklearn.model_selection import GroupKFold

# サイト列を作成
df['site'] = df['State'] + '_' + df['Sampling_Date']

# GroupKFold（5分割）
gkf = GroupKFold(n_splits=5)
for fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups=df['site'])):
    df.loc[val_idx, 'fold'] = fold
```

### GroupKFold（5分割）の分割結果

| Fold | Train画像数 | Trainサイト数 | Val画像数 | Valサイト数 |
|------|------------|--------------|----------|------------|
| 0 | 284 | 24 | 73 | 6 |
| 1 | 285 | 24 | 72 | 6 |
| 2 | 290 | 24 | 67 | 6 |
| 3 | 284 | 24 | 73 | 6 |
| 4 | 285 | 24 | 72 | 6 |

各foldで約6サイト（70画像程度）がvalidationに回り、残りの24サイト（約285画像）で学習する。

### 各foldのvalidationサイト詳細

- **Fold 0**: WA_2015/9/1, Tas_2015/5/18, NSW_2015/5/7, Vic_2015/8/18, Vic_2015/7/1, Vic_2015/10/14
- **Fold 1**: Tas_2015/9/11, Vic_2015/9/30, Vic_2015/6/30, Tas_2015/11/9, NSW_2015/2/24, WA_2015/7/8
- **Fold 2**: Tas_2015/9/4, NSW_2015/4/1, Vic_2015/6/26, Vic_2015/8/19, Tas_2015/7/1, Vic_2015/10/13
- **Fold 3**: NSW_2015/1/15, Tas_2015/6/29, Vic_2015/8/14, WA_2015/8/21, NSW_2015/10/6, Tas_2015/9/3
- **Fold 4**: Vic_2015/7/2, Tas_2015/5/19, Vic_2015/9/29, Tas_2015/6/26, Tas_2015/11/10, NSW_2015/2/25

### 各foldのState分布

| Fold | Val画像数 | Tas | Vic | NSW | WA |
|------|----------|-----|-----|-----|-----|
| 0 | 73 | 22 | 26 | 13 | 12 |
| 1 | 72 | 29 | 16 | 15 | 12 |
| 2 | 67 | 26 | 31 | 10 | **0** |
| 3 | 73 | 19 | 18 | 28 | 8 |
| 4 | 72 | 42 | 21 | 9 | **0** |

Fold 2, 4でWAが含まれないが、WAのサンプル数が少ない（32画像、3日のみ）ため避けられない。

---

## StratifiedGroupKFoldの検討（不採用）

### 検討した代替案

「Stateで層化 + Sampling_Dateでグループ化」により、各foldでStateの分布を均等にできないか検討した。

```python
from sklearn.model_selection import StratifiedGroupKFold

sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)
for fold, (train_idx, val_idx) in enumerate(sgkf.split(df, df['State'], groups=df['Sampling_Date'])):
    df.loc[val_idx, 'fold'] = fold
```

### 検証結果

| Fold | Val画像数 | Val日数 | State分布 |
|------|----------|--------|-----------|
| 0 | 80 | 6 | NSW:51, Vic:29 |
| 1 | 52 | 4 | Tas:29, WA:12, Vic:11 |
| 2 | 56 | 5 | Vic:30, Tas:26 |
| 3 | 68 | 7 | Tas:31, NSW:15, Vic:14, WA:8 |
| 4 | 101 | 6 | Tas:52, Vic:28, WA:12, NSW:9 |

**結果：Stateの分布がより偏ってしまった（一部foldで2州のみ）**

### 原因：日付と州の1対1関係

| 日付の種類 | 日数 |
|-----------|-----|
| 1州のみで撮影された日 | **26日** |
| 複数州で撮影された日 | 2日（2015/6/26, 2015/7/1のみ） |

ほとんどの日付が1つの州でしか撮影されていないため：
- 日付をグループにすると → その日は1つの州のデータしかない
- Stateで層化しようとしても → グループ内に1つの州しかないので調整不可能

### 結論

**site（State × Sampling_Date）でのGroupKFoldを採用**

- 30サイトに細分化されているため、より柔軟に分割できる
- 日付でグループ化すると粒度が粗くなり、Stateの偏りが大きくなる
- StratifiedGroupKFoldは本データセットの特性上、効果がない

---

## 通常KFold vs GroupKFold の比較

### 期待されるCV評価の違い

| 方式 | CV評価 | 本番との関係 |
|------|--------|-------------|
| 通常KFold | 高め（楽観的） | 本番で未知サイトが来ると期待より悪い |
| GroupKFold | 低め（保守的） | 本番性能の下限を見積もれる |

### 本番での挙動予測

GroupKFoldでCVを評価した場合：
- **本番で未知サイトが来た場合** → CVで見積もった性能程度
- **本番で既知サイトが来た場合** → CVより良い性能（嬉しい誤算）

---

## 注意事項

### テストデータの構成が不明

test.csvにはState, Sampling_Dateの情報が含まれていないため、テストデータが既知サイトか未知サイトかは不明。

### 実践的なアプローチ

1. **両方でCV評価**: 通常KFoldとGroupKFoldの両方でスコアを算出
2. **LBとの相関を確認**: 数回submitしてどちらのCVがLBと相関が高いか確認
3. **保守的に行くなら**: GroupKFoldを採用（最悪ケースを見積もる）

---

## 結論

1. **サイト（State × Sampling_Date）内のデータは、ターゲット値が似ている傾向がある**ことがデータ分析で確認された
2. **通常KFoldでは楽観的な評価になる**可能性が高い
3. **未知サイトへの汎化性能を正しく評価するには、GroupKFoldを推奨**
4. テストデータの構成が不明なため、LBとの相関を確認しながらCV戦略を調整することが望ましい

---

## 参考：実装時の変更箇所

`experiments/001/train.py` の `create_folds` 関数を拡張し、GroupKFoldに対応させる必要がある。

```python
from sklearn.model_selection import GroupKFold

def create_folds(
    df: pd.DataFrame,
    n_folds: int = 5,
    seed: int = 42,
    group_col: str | None = None,  # 追加
) -> pd.DataFrame:
    """Create fold column in dataframe."""
    df = df.copy()
    df["fold"] = -1

    if group_col and group_col in df.columns:
        # Group K-Fold
        gkf = GroupKFold(n_splits=n_folds)
        for fold, (_, val_idx) in enumerate(gkf.split(df, groups=df[group_col])):
            df.loc[val_idx, "fold"] = fold
    else:
        # Standard K-Fold
        kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)
        for fold, (_, val_idx) in enumerate(kf.split(df)):
            df.loc[val_idx, "fold"] = fold

    return df
```

また、Wide形式に変換する前にsite列を作成しておく必要がある：

```python
# サイト列を作成（Long形式の時点で）
train_df['site'] = train_df['State'] + '_' + train_df['Sampling_Date']

# Wide形式に変換
train_df = convert_long_to_wide(train_df)

# GroupKFoldでfold作成
train_df = create_folds(train_df, n_folds=n_folds, seed=seed, group_col='site')
```
