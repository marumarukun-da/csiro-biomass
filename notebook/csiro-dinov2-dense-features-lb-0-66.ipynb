{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6e7052",
   "metadata": {
    "papermill": {
     "duration": 0.002874,
     "end_time": "2025-11-29T02:44:43.524344",
     "exception": false,
     "start_time": "2025-11-29T02:44:43.521470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸŒ¿ðŸŒ± CSIRO Biomass Regression using Dense Features of DINOv2\n",
    "\n",
    "- Use the dense patch-based features extracted by the DINOv2 model\n",
    "- For each patch feature vector, use a common MLP (with weight sharing) to make predictions for each patch\n",
    "- Average the MLP predictions for each patch to obtain final predictions\n",
    "- Uses sharpness-aware minimization (https://github.com/davda54/sam) for training (training code not shown here)\n",
    "- Computes loss only on image-level labels (TODO: incorporate regularizations to make the problem more well-conditioned, or use other methods to compute loss on patch-level labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b34d0b",
   "metadata": {
    "papermill": {
     "duration": 0.001928,
     "end_time": "2025-11-29T02:44:43.528506",
     "exception": false,
     "start_time": "2025-11-29T02:44:43.526578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d002f840",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-29T02:44:43.533444Z",
     "iopub.status.busy": "2025-11-29T02:44:43.533214Z",
     "iopub.status.idle": "2025-11-29T02:44:53.570901Z",
     "shell.execute_reply": "2025-11-29T02:44:53.570137Z"
    },
    "papermill": {
     "duration": 10.041773,
     "end_time": "2025-11-29T02:44:53.572246",
     "exception": false,
     "start_time": "2025-11-29T02:44:43.530473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/kaggle/input/rsna-models/facebookresearch_dinov2_main (1)/root/.cache/torch/hub/facebookresearch_dinov2_main': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers==4.57.1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "!cp -r \"/kaggle/input/rsna-models/facebookresearch_dinov2_main (1)/root/.cache/torch/hub/facebookresearch_dinov2_main\" /kaggle/working/dinov2\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5937998",
   "metadata": {
    "papermill": {
     "duration": 0.002157,
     "end_time": "2025-11-29T02:44:53.576806",
     "exception": false,
     "start_time": "2025-11-29T02:44:53.574649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load DINOv2 backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9443224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T02:44:53.582821Z",
     "iopub.status.busy": "2025-11-29T02:44:53.581889Z",
     "iopub.status.idle": "2025-11-29T02:45:39.600821Z",
     "shell.execute_reply": "2025-11-29T02:45:39.600198Z"
    },
    "papermill": {
     "duration": 46.023377,
     "end_time": "2025-11-29T02:45:39.602296",
     "exception": false,
     "start_time": "2025-11-29T02:44:53.578919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/kaggle/working/dinov2'\n",
      "/kaggle/working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 02:44:58.322067: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764384298.532529      27 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764384298.591415      27 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/dinov2\n",
    "import torch.nn as nn\n",
    "from transformers import Dinov2Model\n",
    "model = Dinov2Model.from_pretrained('/kaggle/input/dinov2/pytorch/giant/1')\n",
    "model.head = nn.Identity()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b01be3e",
   "metadata": {
    "papermill": {
     "duration": 0.002455,
     "end_time": "2025-11-29T02:45:39.607733",
     "exception": false,
     "start_time": "2025-11-29T02:45:39.605278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MLP Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33c2a75d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T02:45:39.613779Z",
     "iopub.status.busy": "2025-11-29T02:45:39.613287Z",
     "iopub.status.idle": "2025-11-29T02:45:39.618245Z",
     "shell.execute_reply": "2025-11-29T02:45:39.617638Z"
    },
    "papermill": {
     "duration": 0.009174,
     "end_time": "2025-11-29T02:45:39.619222",
     "exception": false,
     "start_time": "2025-11-29T02:45:39.610048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class BiomassMLP(nn.Module):\n",
    "    # and also weight initialization\n",
    "    def __init__(self, input_size, hidden_size=512, dropout_rate=0.3):\n",
    "        super(BiomassMLP, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size // 4),\n",
    "            #nn.BatchNorm1d(hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size // 4, 1)\n",
    "        )\n",
    "        #self.network = nn.Linear(input_size, 1) # use a simple MLP with a single activation function, or a polynomial function\n",
    "        #self.network = SimplePolynomialLayer(input_size)\n",
    "    def forward(self, x):\n",
    "        #return self.network(x)\n",
    "        return torch.mean(torch.relu(self.network(x)), dim=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5234deb9",
   "metadata": {
    "papermill": {
     "duration": 0.002386,
     "end_time": "2025-11-29T02:45:39.623967",
     "exception": false,
     "start_time": "2025-11-29T02:45:39.621581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference\n",
    "\n",
    "- TTA (test-time augmentation) is incorporated into the inference\n",
    "- The augmentations include horizontal / vertical flips, rotations, and Gaussian blurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe62c886",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T02:45:39.629580Z",
     "iopub.status.busy": "2025-11-29T02:45:39.629376Z",
     "iopub.status.idle": "2025-11-29T02:45:39.632623Z",
     "shell.execute_reply": "2025-11-29T02:45:39.632095Z"
    },
    "papermill": {
     "duration": 0.007309,
     "end_time": "2025-11-29T02:45:39.633595",
     "exception": false,
     "start_time": "2025-11-29T02:45:39.626286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping = {\"Dry_Clover_g\": 0, \"Dry_Dead_g\": 1, \"Dry_Green_g\": 2, \"Dry_Total_g\": 3, \"GDM_g\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55edb24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T02:45:39.639328Z",
     "iopub.status.busy": "2025-11-29T02:45:39.639080Z",
     "iopub.status.idle": "2025-11-29T02:45:41.686053Z",
     "shell.execute_reply": "2025-11-29T02:45:41.685219Z"
    },
    "papermill": {
     "duration": 2.051367,
     "end_time": "2025-11-29T02:45:41.687324",
     "exception": false,
     "start_time": "2025-11-29T02:45:39.635957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "test_embeds = {}\n",
    "counter = 0\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std)])\n",
    "test_df = pd.read_csv(\"/kaggle/input/csiro-biomass/test.csv\")\n",
    "augmentation_transforms = [\n",
    "    transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std), torchvision.transforms.GaussianBlur(5)]),  # Original\n",
    "    transforms.Compose([transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std), torchvision.transforms.GaussianBlur(5)]),  # Horizontal flip\n",
    "    transforms.Compose([transforms.RandomVerticalFlip(p=1.0), transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std), torchvision.transforms.GaussianBlur(5)]),  # Vertical flip\n",
    "    transforms.Compose([transforms.RandomHorizontalFlip(p=1.0), transforms.RandomVerticalFlip(p=1.0), transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std), torchvision.transforms.GaussianBlur(5)]),  # Both flips\n",
    "    transforms.Compose([transforms.RandomRotation(degrees=90), transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std), torchvision.transforms.GaussianBlur(5)]),  # 90 degree rotation\n",
    "    transforms.Compose([transforms.RandomRotation(degrees=270), transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std), torchvision.transforms.GaussianBlur(5)]),  # 270 degree rotation\n",
    "]\n",
    "root = \"/kaggle/input/csiro-biomass/\"\n",
    "sample_ids = []\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(len(test_df))):\n",
    "    entry = test_df.iloc[i]\n",
    "    file_path = root + entry['image_path']\n",
    "    sample_id = entry['sample_id']\n",
    "    #y = torch.tensor([[entry['target']]])\n",
    "    if sample_id.split(\"_\")[0] not in sample_ids:\n",
    "        image_embeddings = []\n",
    "        for aug in augmentation_transforms:\n",
    "            img = Image.open(file_path)\n",
    "            x = aug(img).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                x = x.cuda()\n",
    "                image_embeddings.append(torch.cat([model(x).last_hidden_state[:,1:,:].cpu()[0]]).unsqueeze(0))\n",
    "                counter += 1\n",
    "        #print(image_embeddings[0].shape, sample_id)\n",
    "        test_embeds[sample_id.split(\"_\")[0]] = torch.stack(image_embeddings, dim=0)\n",
    "        #print(torch.stack(image_embeddings, dim=0).shape)\n",
    "        sample_ids.append(sample_id.split(\"_\")[0])        \n",
    "    if counter % 100 == 0:\n",
    "        print(f\"{counter} batches processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd1d2521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T02:45:41.693782Z",
     "iopub.status.busy": "2025-11-29T02:45:41.693566Z",
     "iopub.status.idle": "2025-11-29T02:45:42.142819Z",
     "shell.execute_reply": "2025-11-29T02:45:42.142052Z"
    },
    "papermill": {
     "duration": 0.454052,
     "end_time": "2025-11-29T02:45:42.144266",
     "exception": false,
     "start_time": "2025-11-29T02:45:41.690214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "regressors = [[None for i in range(5)] for j in range(5)]\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        regressors[i][j] = torch.load(f\"/kaggle/input/csiro-mlps-run1/target{i}/fold{j}.pt\", weights_only=False)\n",
    "import joblib\n",
    "(selected_features, scalers) = joblib.load(\"/kaggle/input/csiro-mlps-run1/sfs_scalers_run1.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181b4bbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T02:45:42.150862Z",
     "iopub.status.busy": "2025-11-29T02:45:42.150434Z",
     "iopub.status.idle": "2025-11-29T02:45:42.340179Z",
     "shell.execute_reply": "2025-11-29T02:45:42.339538Z"
    },
    "papermill": {
     "duration": 0.194401,
     "end_time": "2025-11-29T02:45:42.341505",
     "exception": false,
     "start_time": "2025-11-29T02:45:42.147104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "sample_ids = []\n",
    "test_df = pd.read_csv(\"/kaggle/input/csiro-biomass/test.csv\")\n",
    "for i in range(len(test_df)):\n",
    "    entry = test_df.iloc[i]\n",
    "    X = test_embeds[entry['sample_id'].split(\"__\")[0]]\n",
    "    sample_ids.append(entry['sample_id'])\n",
    "    models = regressors[mapping[entry['sample_id'].split(\"__\")[1]]]\n",
    "    sfs = selected_features[mapping[entry['sample_id'].split(\"__\")[1]]]\n",
    "    scaler_list = scalers[mapping[entry['sample_id'].split(\"__\")[1]]]\n",
    "    prediction = 0.0\n",
    "    for i in range(len(models)):\n",
    "        item = models[i]\n",
    "        scaler = scaler_list[i]\n",
    "        sf = sfs[i]\n",
    "        item.eval()\n",
    "        #print(data)\n",
    "        #print(item)\n",
    "        #print(item(data))\n",
    "        #print(data.shape)\n",
    "        single_pred = torch.mean(torch.relu(item(X.squeeze(1).cuda())))\n",
    "        #single_pred = item(torch.tensor(scaler.transform(X[:,sf])))\n",
    "        if single_pred < 0.0:\n",
    "            single_pred = 0.0\n",
    "        prediction += single_pred.cpu()\n",
    "    prediction = prediction / 5\n",
    "    predictions.append(float(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90c4244d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T02:45:42.348008Z",
     "iopub.status.busy": "2025-11-29T02:45:42.347766Z",
     "iopub.status.idle": "2025-11-29T02:45:42.371352Z",
     "shell.execute_reply": "2025-11-29T02:45:42.370581Z"
    },
    "papermill": {
     "duration": 0.028195,
     "end_time": "2025-11-29T02:45:42.372539",
     "exception": false,
     "start_time": "2025-11-29T02:45:42.344344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1001187975__Dry_Clover_g</td>\n",
       "      <td>1.211414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1001187975__Dry_Dead_g</td>\n",
       "      <td>18.187826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1001187975__Dry_Green_g</td>\n",
       "      <td>27.049255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1001187975__Dry_Total_g</td>\n",
       "      <td>49.601337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1001187975__GDM_g</td>\n",
       "      <td>25.344522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id     target\n",
       "0  ID1001187975__Dry_Clover_g   1.211414\n",
       "1    ID1001187975__Dry_Dead_g  18.187826\n",
       "2   ID1001187975__Dry_Green_g  27.049255\n",
       "3   ID1001187975__Dry_Total_g  49.601337\n",
       "4         ID1001187975__GDM_g  25.344522"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "submission = pd.DataFrame({\n",
    "    'sample_id': sample_ids,\n",
    "    'target': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "isSourceIdPinned": false,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 8679417,
     "isSourceIdPinned": true,
     "sourceId": 13846405,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 986,
     "modelInstanceId": 3329,
     "sourceId": 4537,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 65.923252,
   "end_time": "2025-11-29T02:45:45.909793",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-29T02:44:39.986541",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
